# BrandProbe

BrandProbe is a modular framework for auditing LLM sentiment, optimized for Jupyter Notebooks using `uv` for fast environment management.

## ðŸŒŸ Overview

The framework evaluates LLM outputs based on a robust **3D Cube Methodology**. This approach measures sentiment across different combinations of:
1. **Targets**: The brands or entities being evaluated.
2. **Methodologies**: The prompting strategy used (Direct, Adversarial, Implicit).
3. **Test Cases**: The specific questions or prompts posed to the model (e.g., Recommendation, Core Value).
4. **Personas**: The simulated identities assumed by the LLM (e.g., Gen Z Activist, Frugal Retiree).

By executing across the Cartesian product of these dimensions, BrandProbe ensures comprehensive and unbiased sentiment analysis without conversation history contamination.

## ðŸš€ Installation & Setup

Ensure you have [`uv`](https://github.com/astral-sh/uv) installed, then set up the project:

```bash
# 1. Initialize the project dependencies
uv sync

# 2. Register the Jupyter kernel for Notebook usage
uv run python -m ipykernel install --user --name=brandprobe --display-name "Python (BrandProbe)"
```

## ðŸ—ï¸ Architecture

The package is divided into several clear, modular components under `brandprobe/`:
- **`engines.py`**: Contains `BaseEngine` and wrappers for Azure OpenAI and standardized OpenAI (Ollama-compatible) models.
- **`probers.py`**: A library of f-string templates containing the predefined `PERSONAS` and `TEST_CASES`.
- **`scorers.py`**: Evaluation logic containing `SentimentWrapper` (TextBlob polarity) and `ReliabilityLayer` (Consistency/Hallucination checks).
- **`runner.py`**: The main orchestrator that runs the stateless 3D Cube evaluation and returns a structured pandas DataFrame.

## ðŸ’» Usage

To confirm that the framework is working and properly generating the Cartesian product of prompts:

```bash
uv run verify_cube.py
```
This script uses a mock engine to generate 150 rows of test results (2 Targets Ã— 3 Methodologies Ã— 5 Test Cases Ã— 5 Personas) and exports the data to `cube_results.csv`.

Once verified, you can replace `MockEngine` with `AzureOpenAIEngine` or `OpenAIEngine` using your real API keys to begin auditing LLMs in your Jupyter Notebooks!

### Using `AzureOpenAIEngine`

To audit a model hosted on Azure OpenAI, you must provide your Azure endpoint details. Here is an example of running a shortened 3D Cube using `AzureOpenAIEngine`:

```python
import os
from brandprobe import Runner, AzureOpenAIEngine

# Using environment variables is recommended for API keys
api_key = os.getenv("AZURE_OPENAI_API_KEY", "your-azure-api-key")
endpoint = os.getenv("AZURE_OPENAI_ENDPOINT", "https://your-resource.openai.azure.com/")
deployment_name = "gpt-4-deployment" # the name of your specific deployment
api_version = "2024-02-15-preview" # standard Azure OpenAI api-version

# Initialize engine
engine = AzureOpenAIEngine(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=endpoint,
    deployment_name=deployment_name
)

# Set up orchestrator
runner = Runner(engine)

# Define criteria
targets = ["BrandA", "BrandB"]
methodologies = ["Direct"]
test_cases = ["Recommendation", "Value"]
personas = ["Gen Z Activist"]

# Execute Cube
df = runner.run_cube(targets, methodologies, test_cases, personas)

# View results
print(df.head())
```

---

## ðŸ‘¤ Author

**Dimitrios Panagopoulos** Specialist in AI Sentiment Research & Prompt Engineering.

- **Personal Webpage:** [dpanagop.github.io](https://dpanagop.github.io/)
- **LinkedIn:** [dpanagopoulos](https://www.linkedin.com/in/dpanagopoulos/)

---

## âš–ï¸ Licensing & Attribution

This project is **dual-licensed** to ensure software flexibility while protecting intellectual property and requiring research attribution:

1. **The Code:** Licensed under the [MIT License](LICENSE).
2. **The Methodology & Personas:** The 3D Cube framework and persona library are licensed under [Creative Commons Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/).

### How to Attribute
If you use this framework or the persona library in a public report, project, or publication, please attribute as follows:
> "BrandProbe methodology and research framework developed by [Dimitris Panagopoulos](https://dpanagop.github.io/)."

### Disclaimer
*This software is provided "as is", without warranty of any kind. The sentiment analysis results are generated by third-party AI models and do not represent the views of the author. The author is not responsible for how users interpret or act upon the generated data.*